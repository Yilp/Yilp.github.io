[{"title":"英语单词","date":"2022-08-23T00:47:33.000Z","path":"2022/08/23/英语单词/","text":"记录不认识的单词 colums 列 rows 行 Flip and Crop 翻转和裁剪 saturation 饱和度 hue 色调, 色彩, 颜色 Horizontal 水平的 ratio 比率 image augmentation 图像增广 （啊哥美tation） subscriptable 可下标的 horizontal 水平的 hue 色调","tags":[]},{"title":"Linux常用命令","date":"2022-08-22T08:52:10.000Z","path":"2022/08/22/Linux常用命令/","text":"Linux常用命令记录一些常用命令 重启：init 6或 reboot（虚拟机上） 关机： init0或 halt 清屏： clear 查看服务器地址：ip addr 时间： date 复制粘贴：Ctrl+insert Shift+ins 终止命令： ctrl +c 目录 pwd 查看当前目录 cd 目录名 进入目录 cd .. 进入上级目录 cd 进入主目录 ls 列出当前目录 ls -l 列出当前目录详细信息 (显示的d是目录，-是文件) 目录和文件有严格的权限 ls -l 具体目录 ls /具体目录 “./“：代表目前所在的目录。 “ . ./“代表上一层目录。 “/“：代表根目录。 正则表达式： *匹配任意字符 ls _f* 列出某类文件 ls _*.h ls *.h ？匹配一个字符 ls -lt 按时间降序 创建目录 mkdir aaa/bbb 使用的当前目录 ， mkdir /aaa/bbb 删除目录 rm -r aaa -r 删除目录 rm -rf aaa -r删除目录不询问 rm bbb 删除文件 rm -f bbb 删除文件不提示 移动文件目录 选择文件或者目录 mv 名字 重命名 然后 mv 重命名 目录 复制 cp 和删除目录一样的有r 打包和压缩 打包 tar zcvf 压缩后的文件名.tgz（绝对路径） 目录、文件 解压 ta zxvf tar打包的文件，winar可以打开 文本内容 显示内容 cat、more和tail。 cat 文件名，一次显示整个文件的内容。 more 文件名 ，分页显示，按空格键显示下一页，按b键显上一页，按q键退出。 tail -f 文件名 显示最后几行，如果文件的内容有增加，就实时的刷新 搜索内容 搜索文件中的内容 grep “内容” 文件名 grep max .c 在.c文件中搜索max内容 搜索文件 find 目录名 -name 文件名 -print 目录名：待搜索的目录，搜索文件的时候，除了这个目录名，还包括它的各级子目录。 文件名：待搜索的文件名匹配的规则。 su - root 切换root用户 su - 用户名 df [-h] [-T] 选项-h 以方便阅读的方式显示信息。 选项-T 列出文件系统类型 目录和文件 可以看作只有一个盘 Windows下\\ Linux / 文件名严格讲是由目录+文件名组成，绝对目录是从 \\根 算起 登录Linux时，处于目录树的某个目录下，这个目录为当前目录 相对路径是从当前目录算起的，如 /a/b/c.text , 当前目录为/a/b, c.txt = /a/b/c.text . 当前目录 .. 当前目录的上一级目录","tags":[{"name":"Linux","slug":"Linux","permalink":"https://yilp.github.io/tags/Linux/"}]},{"title":"python语法记录","date":"2022-08-11T06:35:16.000Z","path":"2022/08/11/python语法记录/","text":"记录python不熟悉的语法 1.if name == ‘__main__‘：一个Python文件有两种运行方式，1个是作为脚本直接运行，另一个是作为模块import，而if name == ‘__main__‘ 里的代码只有在第1个的情况下才会运行。 123456print(&quot;one&quot;)if __name__ == ‘__main__‘: print(&quot;two&quot;)# 结果如下# one# two 原理是作为模块导入时， 123__name__ # 指模块的名称__main__ # 永远指当前运行的脚本__name__ ！= ‘__main__‘ 2.time.clock()，代码提示有该属性，但就是报错1time.perf_counter() #替换即可计时 3.if isinstance(X, list):判断变量类型的函数，既可以是python内置的数据类型如 list、dict、str，也可以是自定义的类。 4.numel()返回数组中元素的个数 5.apply(), model.apply(fn)或net.apply(fn)任何网络都是 torch.nn.Module 的子类，都算Module。 apply会递归的应用fn到每个子模块，然后是应用到模块本身（即先子后父），返回的是Module 12345678910111213import torch.nn as nn@torch.no_grad()def init_weights(m): print(m) if type(m) == nn.Linear: m.weight.fill_(1.0) print(m.weight)net = nn.Sequential(nn.Linear(2,4), nn.Linear(4, 8))print(net)print(&#x27;isinstance torch.nn.Module&#x27;,isinstance(net,torch.nn.Module))print(&#x27; &#x27;)net.apply(init_weights) 结果 12345678910111213141516171819202122232425262728Sequential( (0): Linear(in_features=2, out_features=4, bias=True) (1): Linear(in_features=4, out_features=8, bias=True))isinstance torch.nn.Module True Linear(in_features=2, out_features=4, bias=True)Parameter containing:tensor([[1., 1.], [1., 1.], [1., 1.], [1., 1.]], requires_grad=True)Linear(in_features=4, out_features=8, bias=True)Parameter containing:tensor([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], requires_grad=True)Sequential( (0): Linear(in_features=2, out_features=4, bias=True) (1): Linear(in_features=4, out_features=8, bias=True)) 6.函数和函数调用的区别f 是一个函数，它的值是函数本身， f( )是函数的调用，它的值是函数的执行结果 在被装饰函数定义阶段，也就是函数调用之前： 7.装饰器python装饰器就是用于拓展原来函数功能的一种函数，这个函数的特殊之处在于它的返回值也是一个函数，使用python装饰器的好处就是在不用更改原函数的代码前提下给函数增加新的功能 123456789101112131415161718192021222324252627282930def dec1(func): print(&quot;1111&quot;) def one(): print(&quot;2222&quot;) func() print(&quot;3333&quot;) return one def dec2(func): print(&quot;aaaa&quot;) def two(): print(&quot;bbbb&quot;) func() print(&quot;cccc&quot;) return two @dec1 @dec2 def test(): print(&quot;test test&quot;) test() # aaaa # 1111 # 2222 # bbbb # test test # cccc # 3333# 不调用test() 也有输出 aaaa 1111 加断点测试更清楚 多个装饰函数的调用顺序 函数定义阶段：执行顺序是从最靠近函数的装饰器开始，自内而外的执行 函数执行阶段：执行顺序由外而内，一层层执行 @b @a 定义时，相当于套盒子，先套a盒子，再套b盒子 使用时，先拆b盒子（b产生了新函数），再拆a盒子（a也产生新盒子） 8.格式化字符串f-stringf-string在形式上是以 f 或 F 修饰符引领的字符串（f&#39;xxx&#39; 或 F&#39;xxx&#39;），以大括号 &#123;&#125; 标明被替换的字段，可以是变量、表达式、函数调用。 注意： —.{}括号里的引号不能与外面的定界符引号发生冲突，可以使用双引号、三引号避免。 —.括号内不能出现转义字符\\，即使要出现，也要用变量代替。 9.%matplotlib inline可以在Ipython编译器里直接使用，功能是可以内嵌绘图，并且可以省略掉plt.show()这一步。 是在使用jupyter notebook 或者 jupyter qtconsole的时候，才会经常用到%matplotlib 而%matplotlib具体作用是当你调用matplotlib.pyplot的绘图函数plot()进行绘图的时候，或者生成一个figure画布的时候，可以直接在你的python console里面生成图像。","tags":[{"name":"python","slug":"python","permalink":"https://yilp.github.io/tags/python/"}]},{"title":"pycharm报错、警告","date":"2022-08-11T02:10:03.000Z","path":"2022/08/11/pycharm报错、警告/","text":"记录使用pycharm时出现错误和警告 1.shadows name ‘xxxx’ from outer scope 警告解决外部有个相同名称的变量在方法内部被重新指定了新的值，也就是说你在外部的相同名称的变量压根就没有任何作用。所以PyCharm就回提示这个信息。这个时候就需要我们去调整具体代码了。 123456def a(): param = &#x27;b&#x27; # 这里就会出现这样的提示，因为在main定义的param对象被重新指定了新的值 print paramif __name__ == &#x27;__main__&#x27;: param = &#x27;a&#x27; a() 2.RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase. This probably means that you are not using fork to start your child processes and you have forgotten to use the proper idiom in the main module: if __name__ == &#39;__main__&#39;: freeze_support() ... The &quot;freeze_support()&quot; line can be omitted if the program is not going to be frozen to produce an executable. 3.module ‘torch.optim’ has no attribute ‘sgd’虽然代码提示有sgd属性，但实际没有，只有SGD 4.TypeError: ‘tuple’ object does not support item assignmentTuple：tuple是另一种有序的列表，也称为“ 元组 ”。tuple 和 list 非常类似，但是，tuple一旦创建完毕，就不能修改了。 创建tuple和创建list唯一不同之处是用( )替代了[ ]。 获取 tuple 元素的方式和 list 是一模一样的，我们可以正常使用 t[0]，t[-1]等索引方式访问元素，但是不能赋值成别的元素，也不能增加删减元素。 tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。指向‘a’，就不能指向’b’。如果指向list，就不能改成指向其他对象，但指向的这个list本身是可变的！ 5.one of the variables needed for gradient computation has been modified by an inplace operation计算梯度的时候检查出某个Variable有被一个 inplace operation 修改。是反向传播的过程中出错的。 inplace operation 就是直接对tensor的内容进行修改，而没有使用复制的副本 （An in-place operation is an operation that changes directly the content of a given Tensor without making a copy）。 在pytorch中， inplace operation 可以是一些 .add_() 或 .scatter_() 导致的。对于.add_()方法，是直接在tensor上进行修改的，可以把x.add_(y)改成x = x + y。如果需要复制一个副本话，可以使用.clone()方法。 在python中， inplace operation 可以是一些 += 或 *= 导致的。比如 x += y，需要改成 x = x +y 6.TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists;报错原因：没有将数据转为torch的Tensor数据类型。 解决方法：读取数据集时将数据转为Tensor数据类型即可 12345678910111213141516# 最开始def load_cifar10(is_train, augs, batch_size): &quot;&quot;&quot;读取图像和应用图像增广&quot;&quot;&quot; dataset = torchvision.datasets.CIFAR10(root=&quot;../data&quot;, train=is_train,) dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=is_train, num_workers=2) return dataloader# 修改为def load_cifar10(is_train, augs, batch_size): &quot;&quot;&quot;读取图像和应用图像增广&quot;&quot;&quot; dataset = torchvision.datasets.CIFAR10(root=&quot;../data&quot;, train=is_train, transform=torchvision.transforms.ToTensor()) dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=is_train, num_workers=2) return dataloader 7.cannot unpack non-iterable NoneType object报错原因：将单个 None 赋给了多个值。 12345678910value = 0def test(): if value == 1: a = b = 1 return a, b# 无返回值时，返回Nonea, b = test()print(a, b) 解决方法 大多数情况是程序写错了导致返回的None，如果真的会返回None加入else 返回其他任意类型值，但注意得返回2个 8.RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same报错原因： 输入的数据类型为torch.cuda.FloatTensor，说明输入数据在GPU中 模型参数的数据类型为torch.FloatTensor，说明模型还在CPU 解决方法：将模型加载到gpu model = model.cuda() model = model.to(&#39;cuda&#39;) model.cuda() model.to(&#39;cuda&#39;) 反之就是数据没移到gpu tensor = tensor.cuda() tensor = tensor.to(&#39;cuda&#39;) 但要注意直接tensor.to(&#39;cuda&#39;)等方法不行， 原因：Module.to() 是一个“in-place”方法，tensor.to() 函数不是。tensor.to() 这个函数功能是产生一个新的tensor，并不会改变原数据。 数据在gpu、cpu的调用：x=x.cuda() , x=x.gpu() 9.Tensor object has no attribute cdua将数据移动到gpu时报错，x=x.cuda() ,很奇怪，x=x.to(cuda)没有报错。 过了一会 x=x.cuda() 又能运行了。","tags":[{"name":"python","slug":"python","permalink":"https://yilp.github.io/tags/python/"}]},{"title":"pytorch官方文档查询记录","date":"2022-08-11T01:39:51.000Z","path":"2022/08/11/pytorch官方文档查询记录/","text":"记录查询过官方文档的知识点 1.CONV2D1torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode=&#x27;zeros&#x27;, device=None, dtype=None) in_channels (int) – Number of channels in the input image out_channels (int) – Number of channels produced by the convolution kernel_size (int or tuple) – Size of the convolving kernel stride (int or tuple, optional) – Stride of the convolution. Default: 1 padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0 padding_mode (string, optional) – &#39;zeros&#39;, &#39;reflect&#39;, &#39;replicate&#39; or &#39;circular&#39;. Default: &#39;zeros&#39; dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1 groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1 bias (bool, optional) – If True, adds a learnable bias to the output. Default: True 注意：padding=&#39;valid&#39; is the same as no padding. padding=&#39;same&#39; pads the input so the output has the shape as the input. However, this mode doesn’t support any stride values other than 1. torch默认数据类型float32 2.nn.AdaptiveAvgPool2d（output_size）输出形状可以是H*W，这种可以用一个元组表示(H, W)。 也可以是一个单独的H，表示输出为H*H 也可以是(H，None),None， None表示与输入一样 1234567891011121314# target output size of 5x7m = nn.AdaptiveAvgPool2d((5,7))input = torch.randn(1, 64, 8, 9)output = m(input)# target output size of 7x7 (square)m = nn.AdaptiveAvgPool2d(7)input = torch.randn(1, 64, 10, 9)output = m(input)# target output size of 10x7m = nn.AdaptiveAvgPool2d((None, 7))input = torch.randn(1, 64, 10, 9)output = m(input) 3.torch.nn.BATCHNORM2D在 4D 输入（具有附加通道维度的小批量 2D 输入）上应用批量标准化 12# 默认情况torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) 参数 num_features – C, C 来自于输入 (N, C, H, W)。一般只输入这个参数 eps –稳定系数，防止分母出现0。 Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Default: 0.1 。BatchNorm2d里面存储均值（running_mean）和方差（running_var）更新时的参数。这个动量参数不同于优化器类和传统的动量概念 affine – True代表gamma，beta是否可学。如果设为True，代表两个参数是通过学习得到的；如果设为False，代表两个参数是固定值，默认情况下，gamma是1，beta是0 track_running_stats –BatchNorm2d中存储的的均值和方差是否需要更新，若为True，表示需要更新；反之不需要更新 # With Learnable Parameters m = nn.BatchNorm2d(100) # Without Learnable Parameters m = nn.BatchNorm2d(100, affine=False) input = torch.randn(20, 100, 35, 45) output = m(input) 批量规范化： 对于所有的batch中样本的同一个channel的数据元素进行标准化处理，即样本如果有C个通道，无论batch中有多少个样本，都会在通道维度上进行标准化处理，一共进行C次 训练阶段， track_running_stats=true，模型事先存储了各个通道的均值和方差初始值。每当一个batch的数据规范化时，利用此时计算得到的局部观测值更新存储的均值和方差，使之具有全局数据的统计特性。 测试阶段，track_running_stats=true，模型处于测试阶段，测试数据时，仍要规范化。需要考虑存储的均值和方差，但不会更新。 详细连接：https://blog.csdn.net/ChaoFeiLi/article/details/124847167?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166104928116782395318256%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166104928116782395318256&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduend~default-2-124847167-null-null.nonecase&amp;utm_term=batchnorm2d%E4%BD%9C%E7%94%A8&amp;spm=1018.2226.3001.4450","tags":[{"name":"python","slug":"python","permalink":"https://yilp.github.io/tags/python/"},{"name":"pytorch","slug":"pytorch","permalink":"https://yilp.github.io/tags/pytorch/"}]},{"title":"一间低夹定式","date":"2022-08-10T11:16:19.000Z","path":"2022/08/10/一间低夹定式/","text":"星位的一间低夹定式及双方变化 黑棋夹后，白棋有 点、跳、飞 三种应对方式 一、白棋飞 到这样，白棋又有点三三、 托两种下法 —点1.黑棋扳三三，黑棋出错打吃而没有挡住 2.黑棋打吃，布局结束，黑棋获得先手 —托1.黑棋扳 白棋出错 **2.**黑棋打吃 黑棋扳不满意 二、白棋跳黑棋有尖三三和尖顶白2的下法 但当黑棋下方有棋可以围空的时候，就不应该尖三三，否则后面下法很吃亏 二间低夹时2.二间扳粘跳出去 2.双飞燕 白8应当点三三，而不是长2（黑1挡） 黑9挡白8（白10位置），则黑棋吃亏，白棋满意 黑棋可能的两种下法两种 二间低高夹时点角 双飞燕 跳出来","tags":[{"name":"生活","slug":"生活","permalink":"https://yilp.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"围棋","slug":"围棋","permalink":"https://yilp.github.io/tags/%E5%9B%B4%E6%A3%8B/"}]},{"title":"围棋-邱百瑞","date":"2022-08-07T12:54:40.000Z","path":"2022/08/07/围棋-邱百瑞/","text":"1.基本落子规则和胜利条件黑线白后（黑先对局结束后要还白棋），4星位，中天元 打吃：2口气变1口气 死棋：无气 获胜条件：谁占的交叉点多胜利，地盘大（活棋和包围的地盘），占领地盘的棋子首先得活着 眼:一整块的棋包围的交叉点，下不进去（包围交叉点多就叫“空”，需要学习是否在空、大眼里分割眼，双方就有先手活、后手死等） 眼的叫法根据形状：直三、四，弯三，闪电四，判断、找到同时占领做活的点 大眼：2个做眼（做出两眼）的位置，活//1个做眼的位置，先手活，后手死。0个做眼的位置，死 假眼：看着像眼 活棋：永远不会被吃 线：同一线的棋子属性差不多。最外一圈叫一线。三线和四线的位置是好位置，优先占领。 优先占角：围空花费的棋子、做眼的角度：角上&lt;边上&lt;中央——金角银边草肚皮（棋盘上没棋子时的价值判断）。所以优先下的位置为星位，星位下的位置叫小目，斜对角叫三三 。双方占完角后，朝中央发展 2.行棋步伐封锁线：棋子和棋子和边间隔2个距离就形成了封锁线，就封锁了地盘 步伐：尖（2个棋子斜着，结实）、飞（2个棋子马，快），大飞，超大飞，拆一（横着间隔），跳（竖着从一条线到另一条线），立（2个挨着） 打劫：被吃了不能立马吃回来，必须在外下一手 3.棋子间的联系1个棋子基本能影响4个气和4个斜角（下棋先做到不吃亏），一般情况下行棋有分寸，对方一个棋子，我们下棋距离1个距离 和自己的棋子，1个棋子2个距离，2个棋子3个距离。 对方下棋碰上来，逢碰必板（改变对方行进方向） 逢板必退：给自己的棋子长气 扭十字长一边，哪边弱长哪边：出现扭十字后，不要着急进攻。 打吃容易出事情：就是打吃没吃掉，别人气长了，而自己的棋子是分开的， 学这些是明白下棋得有分寸感，和自己、对方的棋子保持距离 4.接触战-连接和分断连接 1.粘，直接下断点将棋子连接 2.斜（尖）：利用围棋规则，有两个断点，对方破坏1个，我们连上另1个 3.虎，下个虎口，虽然棋子没连接，但对方没法下断点 双虎： 4.虎补，通过飞来控制断点 5.双 5.判断棋子重要程度棋筋：起到连接和分段的棋子–优先消灭/保护 废子：对做活没有用，不必理会 干子：普通的子 不要根据数量来判断 判断在先，手段在后 6.吃子技巧–双打吃双打吃：一步棋打吃2个棋子（形成的条件：有断点，气紧-少，所以要自己制造、避免 ） 适用范围：吃棋筋子、大块子 吃子的时候要分析值不值得吃 向下吃：一般针对2、3线的棋子，利用围棋的边界 关门吃： 抱吃： 吃子时追赶敌人把敌人朝着我们强的地方赶 围棋入门-4围地的常识占角拆边围中间 拆二围地比较保险，围三/四线，一般围地的手法是拆二、小飞、大飞（顺序不一） 尖或者小飞守角 -5对杀的常识对杀：互相包围了，只有杀了对方才能活，关键比气 对杀的时候先紧外气（对方的气），不要走到公气，否则等于没走，气多也可能输（眼的那气不算外气）。公气越多，越可能双活。 有眼的和没眼的对杀，几乎不可能双活。有眼的不要走公气，无眼的一定要走完公气后才有可能杀掉对。 对杀时先做眼，阻止对方做眼，做出眼后留出了公气，占优势（公气越多优势越大）。 -6大小与先后手每一手下了都会有价值，下了一子吃了1目，多了1个空格，则价值为2目 单官：下了没有价值 下完了之后把吃了的子放回各自的领地里 先手：下先迫使对方抵挡，先手非常重要 -7关于吃子的几个问题-能杀对方： 兵多 对方断点多 在边上，出路少 同时杀棋时把对方往边上赶，往自己人多地方赶，同时追杀棋时如果出现断点一定要注意，不要盲目杀棋 布局的要领-1占角、挂角、根据地挂角：小飞挂（最常用）、一间高挂、二间高挂 不同位置的挂角： 守角：对星位的守角，小飞、大飞、边角 布局的重要手段：拆（下对方拆的地方，叫架）。两个子就可拆三 -2分投、大场分投：投在对方的阵地，两边都可拆（二） 大场：中间1那个点 -3有关根据 4有关出路快被包围的时候可以跳逃出去 下棋寻找没有安定的棋 占地比吃子更重要 活棋要尽量能照顾其他地方 布局的时候下棋看下的棋和根据地、出路有无关系 -5布局常见错误-拆二、根据和官子 双方已经碰撞了，要注意 围棋眼界要宽阔，要大胆，也不要小小缩边围地 -6布局常见错误-一味围地、劳力重复已经活了的棋不需要照顾， 活棋会师也没有效率 -7布局-三连星小目控角、目外占边、高目中间，星位三者兼顾 初中级常用的布局，非常实用 比如对手在内部小飞挂，尖顶定式，大场继续尖顶进攻挖根 对手小飞挂，我方使用夹攻击，对手点三三，防御得把对手挡在三连星外 -8布局-中国流初期，日本很强，中国在定式这些理论方面很弱，但中盘厮杀能力可以，于是开发出了中国流，针对日本棋手，追求快速布局，进入战斗。 定式的要点-1得失的判断开局情况（双方可以接受） 1、双方一半一半 2、一个实地，一个外势。水平一般要实地实惠，但最好要外势锻炼（股票和现金） 3、直接对杀 -2着手的意义、连络与切断、出头与封头、根据地定式就是包含了 连络与切断、出头与封头、根据地，每手棋基本就这几个作用。 下棋只要符合基本原则就不会出太大的错 出头封头很重要 -3星、小飞挂小飞挂是最常见的 像尖顶定式一般是有棋子防止对面拆二才用 别人打自己弱点，自己也要注意对面弱点，打过去 老老实实下棋没法提升 送对面一子来布局，不得贪吃 定式知道这种下法就行，具体看变化 一打一接 -4小目小飞挂 应对：1.尖守（很稳定） 、小飞、拆二 ​ 2 夹 （现在常用的，对手跳） -5高挂-6目外、高目、三三 死活的关键-1基本手段-扩大与缩小眼位2路六死八活、3路四死六活 二一路很重要 缩小眼位要注意力度够不够 缩小眼位：1. 一路板（如 扑） 2.内部 哪扩大，哪缩小，变成基本型 -2基本手段-做眼和点眼做眼:用最小的地方做个眼 点眼：让对方浪费地方才能做眼，阻止对方做眼 缩眼不行就考虑点眼 扩大眼位不行就做眼 -3基本手段-眼形要点直的眼位和弯的眼位容易活，特别是弯的 方的和圆的容易死 -4基本手段-二一路考虑死活的方案时，还要考虑对方的破坏 要多注意二一路 角上死活很重要的要点 -5基本手段-点方死活时 田的对角 -6基本手段-扑与防扑扑来破眼，比如点眼扑再扑 防扑：想办法吃3子，或者先手吃2子 -7基本形-角部基本型直三·曲三一点死，丁四·刀五一点亡。花五·花六眼虽大，中间一点也白忙。 直四·曲四和板六，够做两眼不用慌。 死棋 多一路（黑棋先板则变死棋形状，所以白棋先得占个二一路就活了） 活棋 活棋 白棋多了个板 黑棋下面先板则白死了，如果黑棋扑则错了，或者黑点方 白棋点二一路 下面有个板 -8基本形-小猪嘴型-9基本形-大猪嘴型-10基本形-金柜角型-11基本形-实战常见型-12基本形-边上基本型中间有气，两边至少有一个有气 盘角曲四 盘角曲四，劫尽棋亡。等到全部单官收完以后，点进去， 对方只好扑劫， 提劫， 此时全场无劫财， 所以是死棋。 所以，盘角曲四得把全局劫材补完后再下，有双活就不一样了。 盘角的曲四五应该都有死的 打劫：谁下谁吃 劫材：打劫后，由于不能立即提回，需在其他地方下一手，如果迫使对方应一手，则可以称这一手为劫材","tags":[{"name":"生活","slug":"生活","permalink":"https://yilp.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"围棋","slug":"围棋","permalink":"https://yilp.github.io/tags/%E5%9B%B4%E6%A3%8B/"}]},{"title":"基于hexo的博客搭建","date":"2022-08-07T12:10:27.000Z","path":"2022/08/07/基于hexo的博客搭建/","text":"1.安装Nodejs官网安装好Nodejs，除了安装路径，一路next安装 123git bash #进入根目录node -v #查看node版本node -v #查看node版本 2.安装hexo框架1234npm install -g cnpm --registry=http://registry.npm.taobao.org #安装淘宝的cnpm 管理器cnpm -v #查看cnpm版本cnpm install -g hexo-cli #安装hexo框架hexo -v #查看hexo版本 3.配置个人博客123456789mkdir blog #创建blog目录 本文件夹包含博客的所有东西，配置出错删除重来即可cd blog #进入blog目录hexo init #生成博客 初始化博客hexo s #启动本地博客服务 访问 http://localhost:4000/ 即可看到本地博客hexo n &quot;我的第一篇文章&quot; #创建新的文章 #返回blog目录 #写、改文章后的必要操作hexo clean #清理hexo g #生成 4.利用GitHub部署到远端12345678910# 创建一个新仓库，命名为 GitHub的用户名.github.iocnpm install --save hexo-deployer-git # 在blog目录下部署git插件#配置blog目录下的 _config.yml 文件----非常重要的文件，后续还可修改博客风格deploy: type: git repo: https://github.com/YourGithubName/YourGithubName.github.io.git branch: masterhexo d #部署到Github仓库里 https://Name.github.io/ 可以查看博客# 每次写好文章后，现在本地服务器查看有无错误，再上传 5.修改主题12345 git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia #下载yilia主题到本地 #修改blog目录下的 _config.yml 文件 ： theme: yilia hexo c #清理一下hexo g #生成hexo d #部署到远程Github仓库 常用命令12345pwd # 显示当前路径cd #更改路径mkdir#创建文件夹cd ../../ #返回上两级目录ls -l #显示文件列表 博客搭好写、传文章12345hexo n &quot;文章名&quot; #改不需要这一步#在本地写好后hexo clean #最好clean 不要hexo ghexo d","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://yilp.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"博客","slug":"博客","permalink":"https://yilp.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"Hexo命令","date":"2022-08-07T07:28:22.556Z","path":"2022/08/07/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://yilp.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"博客","slug":"博客","permalink":"https://yilp.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]}]